{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# MDA 2022\n",
        "## Pyspark Sample Code\n",
        "-----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "## Setup\n",
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's setup Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-qHai2252mI"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJ71AKe91eh"
      },
      "source": [
        "Now we authenticate a Google Drive client to processing data\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K93ABEy9Zlo",
        "outputId": "8edeb2a1-35ba-463a-f36d-bcca540bce87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bK7ob3k4Yd1"
      },
      "source": [
        "## Check and extract data\n",
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT70OpRGzkWh",
        "outputId": "cee8742c-a408-4630-da62-fee1eaa0a987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " checkstatus.csv   MDA_2021.ipynb       SystemID.csv\n",
            " CompanyID.csv\t   Sample_Data.zip      Traffic.csv\n",
            " Data.zip\t   Sample_Traffic.csv  'پروژه MDA2021.pdf'\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks/MDA/HW2/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLoUDlZrzoAg",
        "outputId": "8d6c6cca-23ff-42bc-a6c4-99e93dcc4720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./Sample_Data.zip\n",
            "  inflating: ./Sample_Traffic.csv    \n"
          ]
        }
      ],
      "source": [
        "# !unzip \"/content/drive/My Drive/Colab Notebooks/MDA/HW3/Sample_Data.zip\" -d \"/content/drive/My Drive/Colab Notebooks/MDA/HW2\"\n",
        "!unzip \"./Sample_Data.zip\" -d \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "the cells above, extract data which is in '/content/drive/My Drive/Test' to /content/drive/My Drive/Test/Traffic.csv  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "## Initializing Spark and read data\n",
        "--------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDh957r_0snm",
        "outputId": "9d8551a6-61b6-4bda-9d9f-590c2123773e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21/12/05 20:48:27 WARN Utils: Your hostname, amin-X556UQK resolves to a loopback address: 127.0.1.1; using 192.168.1.15 instead (on interface wlp3s0)\n",
            "21/12/05 20:48:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "21/12/05 20:48:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext, SparkConf \n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,TimestampType\n",
        "from pyspark.sql.functions import col,current_timestamp,to_date,hour,dayofweek\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Spark_Processor\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc=spark.sparkContext\n",
        "\n",
        "schema = StructType([ \\\n",
        "        StructField(\"DEVICE_CODE\", IntegerType(), True), \n",
        "        StructField(\"SYSTEM_ID\",IntegerType(),True), \\\n",
        "        StructField(\"ORIGINE_CAR_KEY\",StringType(),True), \\\n",
        "        StructField(\"FINAL_CAR_KEY\",StringType(),True), \\\n",
        "        StructField(\"CHECK_STATUS_KEY\", IntegerType(), True), \\\n",
        "        StructField(\"COMPANY_ID\", StringType(), True), \\\n",
        "        StructField(\"PASS_DAY_TIME\", TimestampType(), True)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SUqHQTWlqoi"
      },
      "source": [
        "#### Reading Sample_Traffic.cvs File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGoJ3OTX3Lz_",
        "outputId": "4eb0eb19-071a-46d0-bbfe-9a00b87e0aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "|DEVICE_CODE|SYSTEM_ID|ORIGINE_CAR_KEY|FINAL_CAR_KEY|CHECK_STATUS_KEY|COMPANY_ID|      PASS_DAY_TIME|\n",
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "|     200501|       81|       10477885|     10477885|               5|       161|2021-06-01 03:54:39|\n",
            "|        155|       81|       87625017|     87625017|               5|       161|2021-06-01 04:14:21|\n",
            "|     631757|       81|        8652928|      8652928|               5|       161|2021-06-01 03:58:57|\n",
            "|     631757|       81|        8548123|      8548123|               5|       161|2021-06-01 04:01:38|\n",
            "|     631757|       81|       24715264|     24715264|               5|       161|2021-06-01 03:56:57|\n",
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df=spark.read.csv('Sample_Traffic.csv',header=True,schema=schema)\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q943Lbxflqoj"
      },
      "source": [
        "In this part we map the data with key of ('Final_CAR_KEY','PASS_DAY_TIME') and value of ('DEVICE_CODE') which shows the pathway of the cars. Now we have a RDD which has rows that each row contains pathway of each date with license plate of each passed car."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhYYY2TRjgCv",
        "outputId": "3240f0b9-8a19-4d4c-c33b-1386efe9f881"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "data": {
            "text/plain": [
              "[(('10477885', datetime.date(2021, 6, 1)), 200501),\n",
              " (('87625017', datetime.date(2021, 6, 1)), 155),\n",
              " (('8652928', datetime.date(2021, 6, 1)), 631757),\n",
              " (('8548123', datetime.date(2021, 6, 1)), 631757),\n",
              " (('24715264', datetime.date(2021, 6, 1)), 631757)]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = df.rdd.map(lambda x: ((x['FINAL_CAR_KEY'], x['PASS_DAY_TIME'].date()),  x['DEVICE_CODE']))\n",
        "rdd.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nv0WC2tlqok"
      },
      "source": [
        "Now we group_by the above RDD by its key for each car in every date to have all pathway that each car passed in a list. Notice that in this part we use set instead of list to not having repeated pathways. This approach base on the usage of this part does not have huge effect on the whole of the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrTYvjMNku-d",
        "outputId": "9c392bc2-5afb-4fe3-975d-25c9b778df14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "data": {
            "text/plain": [
              "[(('69939810', datetime.date(2021, 6, 1)), {206602, 631830, 900233}),\n",
              " (('11046172', datetime.date(2021, 6, 1)), {206602}),\n",
              " (('29077699', datetime.date(2021, 6, 1)),\n",
              "  {119,\n",
              "   128,\n",
              "   206602,\n",
              "   208602,\n",
              "   210602,\n",
              "   631367,\n",
              "   631763,\n",
              "   631829,\n",
              "   900135,\n",
              "   900233,\n",
              "   900234,\n",
              "   900240,\n",
              "   900246,\n",
              "   900266,\n",
              "   22010111,\n",
              "   22010123}),\n",
              " (('40682798', datetime.date(2021, 6, 1)), {206602}),\n",
              " (('48823778', datetime.date(2021, 6, 1)), {206602})]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd_group = rdd.groupByKey().mapValues(set)\n",
        "rdd_group.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvfBcc4pouA3"
      },
      "source": [
        "# A-Priori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNSClnL1lqol"
      },
      "source": [
        "## Step by Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_1BvXqOlqol"
      },
      "source": [
        "For having baskets, we don't need to keep license plates, so we get baskets without them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcs4hiW_ovuP",
        "outputId": "75385406-d2a9-4a6e-ee67-96a598739c5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "data": {
            "text/plain": [
              "[{206602, 631830, 900233}, {206602}]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "baskets_rdd = rdd_group.map(lambda x: x[1])\n",
        "baskets_rdd.take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCdtIsC8lqol"
      },
      "source": [
        "The below cell is written for testing the algorithm which we can take sample from whole data to run the code faster. The threshold parameter is a ratio of whole baskets which we choose a collection as a frequent collection if it's more than this threshold. \n",
        "I explain about parameters and results in the end of this notebook and also in the report pdf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjHJ97i0ck8e"
      },
      "outputs": [],
      "source": [
        "SAMPLE = True\n",
        "SAMPLE_SIZE = 0.01\n",
        "THRESHOLD = 0.001\n",
        "\n",
        "if SAMPLE:\n",
        "  baskets_rdd = baskets_rdd.sample(True, SAMPLE_SIZE)\n",
        "  baskets_rdd = baskets_rdd.coalesce(10)\n",
        "  baskets_rdd.cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tMi9bpflqom"
      },
      "source": [
        "In the next two cells, we count the number of baskets and then with using threshold, we get minimum support. I explain about MIN_COUNT in the end of this notebook and report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-r_XUYi2Q0c",
        "outputId": "42d0ae69-550e-4dd1-8ba0-7a8ed96feac7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "data": {
            "text/plain": [
              "165"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BASKETS_COUNT = baskets_rdd.count()\n",
        "BASKETS_COUNT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzufIXYR1c4t",
        "outputId": "82807417-f89b-48fb-d168-278d1f36ed1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MIN_COUNT = int(THRESHOLD * BASKETS_COUNT)\n",
        "MIN_COUNT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlPac7m5lqom"
      },
      "source": [
        "In this part at first we get count of repeat of each item and then with using support, we get most frequent items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpmSW_2j0h95",
        "outputId": "4fce733b-f748-4b55-a56d-2952085aa0a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((631363,), 2),\n",
              " ((900171,), 3),\n",
              " ((119,), 5),\n",
              " ((22010087,), 1),\n",
              " ((22010095,), 1)]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frequent_items_rdd = baskets_rdd.flatMap(lambda basket: [((item,),1) for item in basket]).reduceByKey(lambda x,y: x+y).filter(lambda x: x[1] > MIN_COUNT)\n",
        "frequent_items_rdd.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iNJKNk_lqom"
      },
      "source": [
        "This cell count most frequent items number.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsb2aEew1uj2",
        "outputId": "cf9d6dec-b5b2-4a21-f72b-5f02d4c5a206"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "202"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FREQUENT_ITEMS_COUNT = frequent_items_rdd.count()\n",
        "FREQUENT_ITEMS_COUNT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cov5_xLUlqon"
      },
      "source": [
        "## A-Priori Function\n",
        "The next following cells are written for A-Priori function. At first some other functions are written and I explain them in the following and cells and then I write the original function for A-Priori function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMdcdu_Wlqon"
      },
      "source": [
        "#### generate_combinations\n",
        "This function gets frequent itemsets of its previous step and generates candidate of the next step. At first it gets the frequent remaining items from whole of the frequent itemssets and then sort them. Then for each of frequent itemset, it gets the largest element and then compare tp remaining items of the collection and if that item be larger than that one, it adds it to the end of that collection and generates a new candidate. In this function it does'nt need to add smaller elements to the collections.\n",
        "\n",
        "For example, suppose [b,c,d] collection which was frequent in the previous step and the remaining collection of frequent is [a,b,c,d,z] (these elements are sorted). From these remaining elements, z is the only element which is larger than other elements so a new candidate is [b,c,d,z]. But [a,b,c,d] is not a candidate. Assume that it is frequent. We know that all subsets of a frequent set is also frequent. Now if [a,b,c] was frequent, so it would be available in the frequent list and create its combination in checking [a,b,c] but if it isn't frequent, so [a,b,c,d] wouldn't be frequent and was not created correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsbRDDgTlqon"
      },
      "source": [
        "#### get_new_frequents\n",
        "This function gets all the baskets as input and gets the most frequents itemsets of the next step. In this function we get help from a new function which is defined as \"count_freq\" which gets a basket as input and for each candidate of that step, if that candidate exists on that basket, it creates an output as (candidate,1). Finally with counting all candidates, we can get most frequent itemsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79FZkMt320qH",
        "outputId": "ae30799a-571a-42cd-9989-413f9f817fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------loop start----------------------\n",
            "Itemsets of size  2 , count:  732\n",
            "sample: \n",
            "[((208602, 22010060), 1), ((631633, 900269), 1), ((631357, 631633), 1), ((631357, 900269), 1), ((119, 900171), 1), ((22010117, 100700845), 1), ((900233, 22010117), 1), ((900233, 100700845), 1), ((900149, 900233), 1), ((900149, 22010117), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  3 , count:  1772\n",
            "sample: \n",
            "[((900171, 900233, 22010117), 1), ((900171, 900233, 100700845), 1), ((900171, 22010117, 100700845), 1), ((119, 900149, 900233), 1), ((119, 900149, 22010117), 1), ((119, 900149, 100700845), 1), ((119, 900233, 22010117), 1), ((119, 900233, 100700845), 1), ((119, 22010117, 100700845), 1), ((900124, 900160, 900233), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  4 , count:  3518\n",
            "sample: \n",
            "[((119, 900171, 900233, 22010117), 1), ((119, 900171, 900233, 100700845), 1), ((119, 900171, 22010117, 100700845), 1), ((900149, 900233, 22010117, 100700845), 1), ((119, 900124, 900160, 900233), 1), ((119, 900124, 900160, 22010117), 1), ((119, 900124, 900160, 100700845), 1), ((900124, 900149, 900160, 900233), 1), ((900124, 900149, 900160, 22010117), 1), ((900124, 900149, 900160, 100700845), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  5 , count:  5823\n",
            "sample: \n",
            "[((119, 900149, 900233, 22010117, 100700845), 1), ((900124, 900160, 900233, 22010117, 100700845), 1), ((900149, 900171, 900233, 22010117, 100700845), 1), ((119, 900124, 900149, 900160, 900233), 1), ((119, 900124, 900149, 900160, 22010117), 1), ((119, 900124, 900149, 900160, 100700845), 1), ((119, 900124, 900160, 900171, 900233), 1), ((119, 900124, 900160, 900171, 22010117), 1), ((119, 900124, 900160, 900171, 100700845), 1), ((900124, 900149, 900160, 900171, 900233), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  6 , count:  7960\n",
            "sample: \n",
            "[((119, 900124, 900160, 900233, 22010117, 100700845), 1), ((900124, 900149, 900160, 900233, 22010117, 100700845), 1), ((119, 900149, 900171, 900233, 22010117, 100700845), 1), ((900124, 900160, 900171, 900233, 22010117, 100700845), 1), ((119, 900124, 900149, 900160, 900171, 900233), 1), ((119, 900124, 900149, 900160, 900171, 22010117), 1), ((119, 900124, 900149, 900160, 900171, 100700845), 1), ((114, 900101, 900236, 900237, 22010039, 100700841), 1), ((900142, 900152, 900212, 900222, 900244, 100700866), 1), ((631795, 801710, 900124, 900207, 900243, 22010083), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  7 , count:  8889\n",
            "sample: \n",
            "[((119, 900124, 900149, 900160, 900233, 22010117, 100700845), 1), ((119, 900124, 900160, 900171, 900233, 22010117, 100700845), 1), ((900124, 900149, 900160, 900171, 900233, 22010117, 100700845), 1), ((144, 230103, 631795, 801710, 900207, 900243, 22010083), 1), ((144, 230103, 631795, 900102, 900207, 900243, 22010083), 1), ((230103, 631795, 801710, 900124, 900207, 900243, 22010083), 1), ((230103, 631795, 900102, 900124, 900207, 900243, 22010083), 1), ((144, 801710, 900102, 900124, 900207, 900243, 22010083), 1), ((144, 230103, 801710, 900102, 900218, 900243, 22010083), 1), ((144, 631795, 801710, 900102, 900218, 900243, 22010083), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  8 , count:  8032\n",
            "sample: \n",
            "[((119, 900124, 900149, 900160, 900171, 900233, 22010117, 100700845), 1), ((144, 230103, 631795, 801710, 900124, 900218, 900243, 22010083), 1), ((144, 230103, 631795, 900102, 900124, 900218, 900243, 22010083), 1), ((631795, 801710, 900102, 900124, 900207, 900218, 900243, 22010083), 1), ((230103, 801710, 900102, 900124, 900207, 900218, 900243, 22010083), 1), ((144, 230103, 801710, 900124, 900207, 900218, 900243, 22010083), 1), ((144, 230103, 900102, 900124, 900207, 900218, 900243, 22010083), 1), ((144, 631795, 801710, 900124, 900207, 900218, 900243, 22010083), 1), ((144, 631795, 900102, 900124, 900207, 900218, 900243, 22010083), 1), ((144, 230103, 631795, 801710, 900102, 900124, 900207, 900243), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  9 , count:  5806\n",
            "sample: \n",
            "[((144, 230103, 631795, 801710, 900102, 900124, 900207, 900243, 22010083), 1), ((144, 230103, 631795, 801710, 900102, 900207, 900218, 900243, 22010083), 1), ((230103, 631795, 801710, 900102, 900124, 900207, 900218, 900243, 22010083), 1), ((144, 230103, 801710, 900102, 900124, 900218, 900244, 900277, 22010083), 1), ((144, 631795, 801710, 900102, 900124, 900218, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 900124, 900207, 900218, 900244, 900277, 22010083), 1), ((230103, 631795, 801710, 900102, 900207, 900218, 900244, 900277, 22010083), 1), ((631795, 801710, 900124, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((631795, 900102, 900124, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((230103, 801710, 900124, 900207, 900218, 900243, 900244, 900277, 22010083), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  10 , count:  3303\n",
            "sample: \n",
            "[((144, 230103, 801710, 900102, 900124, 900207, 900218, 900244, 900277, 22010083), 1), ((144, 631795, 801710, 900102, 900124, 900207, 900218, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 801710, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 900102, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((230103, 631795, 801710, 900124, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((230103, 631795, 900102, 900124, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((144, 801710, 900102, 900124, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 801710, 900124, 900207, 900243, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 900102, 900124, 900207, 900243, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 801710, 900124, 900207, 900218, 900243, 900277, 22010083), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  11 , count:  1444\n",
            "sample: \n",
            "[((144, 230103, 631795, 801710, 900102, 900124, 900218, 900243, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 801710, 900102, 900124, 900207, 900243, 900244, 900277, 100701266), 1), ((144, 230103, 631795, 801710, 900102, 900207, 900218, 900243, 900244, 900277, 100701266), 1), ((230103, 631795, 801710, 900102, 900124, 900207, 900218, 900243, 900244, 900277, 100701266), 1), ((144, 230103, 631795, 801710, 900102, 900124, 900207, 900218, 900243, 900277, 100701266), 1), ((144, 230103, 631795, 801710, 900124, 900207, 900218, 900243, 900244, 22010083, 100701266), 1), ((144, 230103, 631795, 900102, 900124, 900207, 900218, 900243, 900244, 22010083, 100701266), 1), ((144, 230103, 631795, 801710, 900102, 900124, 900207, 900218, 900277, 22010083, 100701266), 1), ((144, 230103, 801710, 900102, 900124, 900207, 900218, 900243, 900277, 22010083, 100701266), 1), ((144, 631795, 801710, 900102, 900124, 900207, 900218, 900243, 900277, 22010083, 100701266), 1)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  12 , count:  468\n",
            "sample: \n",
            "[((144, 230103, 631795, 801710, 900102, 900124, 900207, 900218, 900243, 900244, 900277, 22010083), 1), ((144, 230103, 631795, 801710, 900124, 900207, 900218, 900243, 900244, 900277, 22010083, 100701266), 1), ((144, 230103, 631795, 900102, 900124, 900207, 900218, 900243, 900244, 900277, 22010083, 100701266), 1), ((230101, 631356, 631831, 900101, 900104, 900152, 900212, 900213, 900217, 900236, 900258, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900152, 900212, 900213, 900217, 900244, 900258, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900236, 900244, 900258, 100700835), 1), ((230101, 631356, 631831, 900104, 900142, 900152, 900212, 900213, 900236, 900244, 900258, 100700835), 1), ((230101, 631356, 631831, 900104, 900142, 900152, 900212, 900217, 900236, 900244, 900258, 100700835), 1), ((230101, 631831, 900101, 900104, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900152, 900213, 900217, 900236, 900244, 900258, 100700835), 1)]\n",
            "-----------------loop start----------------------\n",
            "Itemsets of size  13 , count:  106\n",
            "sample: \n",
            "[((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900236, 900244, 900258, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900217, 900236, 900244, 900258, 100700835), 1), ((230101, 631356, 631831, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 100700835), 1), ((230101, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((631356, 631831, 900101, 900104, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 900101, 900104, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900104, 900142, 900152, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900104, 900142, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900152, 900212, 900213, 900236, 900244, 900258, 900276, 100700835), 1)]\n",
            "-----------------loop start----------------------\n",
            "Itemsets of size  14 , count:  15\n",
            "sample: \n",
            "[((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 100700835), 1), ((230101, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900101, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900142, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276), 1), ((631356, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1), ((230101, 631356, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1)]\n",
            "-----------------loop start----------------------\n",
            "Itemsets of size  15 , count:  1\n",
            "sample: \n",
            "[((230101, 631356, 631831, 900101, 900104, 900142, 900152, 900212, 900213, 900217, 900236, 900244, 900258, 900276, 100700835), 1)]\n",
            "-----------------loop start----------------------\n",
            "Itemsets of size  16 , count:  0\n",
            "sample: \n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "def generate_combinations(old_combinations):\n",
        "  \"\"\"\n",
        "  Input old_frequent_itemsets, and create new candidates from it\n",
        "  \"\"\"\n",
        "\n",
        "  def generate_combinations_util(old_combination):\n",
        "    \"\"\"\n",
        "    lambda function that maps an old combination to a number of new candidate combinations\n",
        "    \"\"\"\n",
        "    old_combination = old_combination[0]\n",
        "    old_combination_max_item = old_combination[-1]\n",
        "\n",
        "    # Can do here numpy way\n",
        "    bigger_items = remaining_items[remaining_items>old_combination_max_item]\n",
        "    new_candidates = []\n",
        "    for x in bigger_items:\n",
        "      new_candidates.append( old_combination + (x,) )\n",
        "\n",
        "    return new_candidates\n",
        "\n",
        "  remaining_items = np.array(old_combinations.flatMap(lambda x: x[0]).distinct().sortBy(lambda x: x).collect())\n",
        "  # print('remaining items: ', remaining_items)\n",
        "\n",
        "  new_combinations = old_combinations.flatMap(generate_combinations_util)\n",
        "  return new_combinations\n",
        "\n",
        "def get_new_frequents(candidates):\n",
        "  # frequent_itemsets_rdd = frequent_itemsets_rdd.filter(lambda x: set(x[0]) <= set(x[1])).map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y).filter(lambda x: x[1]>MIN_COUNT)\n",
        "  \n",
        "  _candidates = candidates.collect()\n",
        "  def count_freq(basket):\n",
        "    candidates_present = []\n",
        "    for candidate in _candidates:\n",
        "      if set(candidate) <= set(basket):\n",
        "        candidates_present.append( (candidate,1) )\n",
        "    \n",
        "    return candidates_present\n",
        "\n",
        "  frequent_itemsets_rdd = baskets_rdd.flatMap(count_freq).reduceByKey(lambda x,y: x+y).filter(lambda x: x[1]>MIN_COUNT)\n",
        "  \n",
        "  return frequent_itemsets_rdd\n",
        "\n",
        "k = 1\n",
        "frequent_itemsets_rdd = frequent_items_rdd\n",
        "while frequent_itemsets_rdd.count() != 0:\n",
        "  print('-----------------loop start----------------------')\n",
        "  k += 1\n",
        "  candidates = generate_combinations(frequent_itemsets_rdd)\n",
        "  frequent_itemsets_rdd = get_new_frequents(candidates)\n",
        "  print('Itemsets of size ', k, ', count: ', frequent_itemsets_rdd.count())\n",
        "  print('sample: ')\n",
        "  print(frequent_itemsets_rdd.take(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8RViOkMlqoo"
      },
      "source": [
        "#### Following cell shows A-Priori algorithm as a function which I explained details in above. The following def will be used for SON algorithm in the next part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV2vaTGllqoo"
      },
      "outputs": [],
      "source": [
        "def apriori(baskets_rdd, MIN_COUNT, verbose=False):\n",
        "  frequent_items_rdd = baskets_rdd.flatMap(lambda basket: [((item,),1) for item in basket]).reduceByKey(lambda x,y: x+y).filter(lambda x: x[1] > MIN_COUNT)\n",
        "\n",
        "  def generate_combinations(old_combinations):\n",
        "    \"\"\"\n",
        "    Input old_frequent_itemsets, and create new candidates from it\n",
        "    \"\"\"\n",
        "\n",
        "    def generate_combinations_util(old_combination):\n",
        "      \"\"\"\n",
        "      lambda function that maps an old combination to a number of new candidate combinations\n",
        "      \"\"\"\n",
        "      old_combination = old_combination[0]\n",
        "      old_combination_max_item = old_combination[-1]\n",
        "\n",
        "      # Can do here numpy way\n",
        "      bigger_items = remaining_items[remaining_items>old_combination_max_item]\n",
        "      new_candidates = []\n",
        "      for x in bigger_items:\n",
        "        new_candidates.append( old_combination + (x,) )\n",
        "\n",
        "      return new_candidates\n",
        "\n",
        "    remaining_items = np.array(old_combinations.flatMap(lambda x: x[0]).distinct().sortBy(lambda x: x).collect())\n",
        "\n",
        "    new_combinations = old_combinations.flatMap(generate_combinations_util)\n",
        "    return new_combinations\n",
        "\n",
        "  def get_new_frequents(candidates):\n",
        "    _candidates = candidates.collect()\n",
        "    def count_freq(basket):\n",
        "      candidates_present = []\n",
        "      for candidate in _candidates:\n",
        "        if set(candidate) <= set(basket):\n",
        "          candidates_present.append( (candidate,1) )\n",
        "\n",
        "      return candidates_present\n",
        "\n",
        "    frequent_itemsets_rdd = baskets_rdd.flatMap(count_freq).reduceByKey(lambda x,y: x+y).filter(lambda x: x[1]>MIN_COUNT)\n",
        "\n",
        "    return frequent_itemsets_rdd\n",
        "\n",
        "  if verbose:\n",
        "    print('MIN_COUNT is: ', MIN_COUNT)\n",
        "  k = 1\n",
        "  frequent_itemsets_rdd = frequent_items_rdd\n",
        "  frequent_itemsets_rdds = []\n",
        "  while frequent_itemsets_rdd.count() != 0:\n",
        "    frequent_itemsets_rdds.append(frequent_itemsets_rdd)\n",
        "    if verbose:\n",
        "      print('-----------------loop start----------------------')\n",
        "    k += 1\n",
        "    candidates = generate_combinations(frequent_itemsets_rdd)\n",
        "    frequent_itemsets_rdd = get_new_frequents(candidates)\n",
        "    if verbose:\n",
        "      print('Itemsets of size ', k, ', count: ', frequent_itemsets_rdd.count())\n",
        "      print('sample: ')\n",
        "      print(frequent_itemsets_rdd.take(10))\n",
        "\n",
        "  return frequent_itemsets_rdds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdQjsSXFlqoo"
      },
      "source": [
        "The following cell is for testing the functionality of the written A-Priori function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkM75pxhlqoo",
        "outputId": "a4930fc0-0e03-469b-a192-c735f1ce2340"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MIN_COUNT is:  15\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  2 , count:  811\n",
            "sample: \n",
            "[((101301, 900101), 30), ((900102, 100701100), 36), ((900182, 100701100), 33), ((145, 100700841), 20), ((900222, 900228), 28), ((900222, 100700868), 171), ((100700866, 100700868), 47), ((900234, 900276), 34), ((900235, 100700871), 41), ((209103, 900235), 18)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  3 , count:  184\n",
            "sample: \n",
            "[((900212, 900244, 22009977), 23), ((631765, 900164, 900276), 17), ((631765, 900164, 100700820), 35), ((631765, 900276, 100700820), 21), ((900101, 900259, 100700841), 35), ((900155, 900222, 100700868), 50), ((205802, 900215, 900234), 19), ((142, 900215, 900234), 16), ((205802, 212802, 900233), 16), ((900215, 900234, 900256), 23)]\n",
            "-----------------loop start----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Itemsets of size  4 , count:  11\n",
            "sample: \n",
            "[((22010087, 22010088, 22010094, 22010095), 28), ((900101, 900212, 900244, 100700839), 16), ((900193, 900212, 900244, 100700839), 16), ((900102, 900142, 900212, 900244), 18), ((900142, 900202, 900212, 900244), 16), ((900142, 900212, 900244, 900249), 17), ((900142, 900212, 900244, 100700853), 54), ((209103, 900265, 100700804, 100700834), 21), ((900142, 900152, 900212, 900244), 18), ((231, 900236, 900255, 100700841), 20)]\n",
            "-----------------loop start----------------------\n",
            "Itemsets of size  5 , count:  0\n",
            "sample: \n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "SAMPLE = True\n",
        "SAMPLE_SIZE = 0.01\n",
        "THRESHOLD = 0.001\n",
        "\n",
        "\n",
        "baskets_rdd = rdd_group.map(lambda x: x[1])\n",
        "\n",
        "if SAMPLE:\n",
        "  baskets_rdd = baskets_rdd.sample(True, SAMPLE_SIZE)\n",
        "  baskets_rdd = baskets_rdd.coalesce(10)\n",
        "  baskets_rdd.cache()\n",
        "\n",
        "BASKETS_COUNT = baskets_rdd.count()\n",
        "BASKETS_COUNT\n",
        "\n",
        "MIN_COUNT = int(THRESHOLD * BASKETS_COUNT)\n",
        "\n",
        "\n",
        "frequent_itemsets_rdds = apriori(baskets_rdd, MIN_COUNT, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X6QgF4qlqop"
      },
      "source": [
        "# SON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8kX4D_7lqop"
      },
      "source": [
        "For SON algorithm, we use the function which I was defined in the last part. For sample in below cell and the support, the application and explanation is the same. In this part,we deploy a random number between 0 to number of partitions-1 which number of partitions shows that RDD will be divided to several parts. Then with filtering on deployed number, RDD will be divided to almost equal partitions. The minimum support of each of these partitions can be reached base on their size (which) are almost equal. Notice that because the size of each partition is small, the minimum support would be small too. For more confidence we multiple the support to 0.9 to not miss anything.\n",
        "\n",
        "Now we deploy A-Priori algorithm in the all parts and then we union the output of these algorithms to get frequent itemsets of the algorithms. But these itemsets may contain false positive because of that we pass through all of the data one more time and count the candidates and filter them. We do this work exactly like A-Priori algorithm.\n",
        "The result of this algorithm was exactly as the same as A-Priori algorithm (Actually we expected this happen because SON algorithm does'nt have false positive and false negative.)\n",
        "\n",
        "So the result of the both algorithm is the same which I report it at the end of the code and also in report PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53mTvnTNSrRH",
        "outputId": "30c707f1-43b1-497b-e3ea-96fca62d59a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MIN_COUNT is:  30408\n",
            "MIN_COUNTS are:  [7589, 7592, 7608, 7580]\n",
            "Itemsets of size  1 , count:  27\n",
            "sample: \n",
            "[((900107,), 38371), ((100700841,), 67632), ((22010119,), 30749), ((100700804,), 33666), ((900155,), 45958), ((900244,), 61075), ((900234,), 31110), ((900268,), 42107), ((900142,), 43822), ((100700866,), 33268)]\n",
            "Itemsets of size  2 , count:  1\n",
            "sample: \n",
            "[((900212, 900244), 42733)]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "baskets_rdd = rdd_group.map(lambda x: x[1])\n",
        "\n",
        "SAMPLE = False\n",
        "SAMPLE_SIZE = 0.01\n",
        "# THRESHOLD = 0.01\n",
        "THRESHOLD = 0.02\n",
        "\n",
        "if SAMPLE:\n",
        "  baskets_rdd = baskets_rdd.sample(True, SAMPLE_SIZE)\n",
        "  baskets_rdd = baskets_rdd.coalesce(10)\n",
        "  baskets_rdd.cache()\n",
        "\n",
        "BASKETS_COUNT = baskets_rdd.count()\n",
        "BASKETS_COUNT\n",
        "\n",
        "MIN_COUNT = int(THRESHOLD * baskets_rdd.count())\n",
        "print('MIN_COUNT is: ', MIN_COUNT)\n",
        "partitions_count = 4\n",
        "def random_lambda(x):\n",
        "    return (x, random.randint(0,partitions_count-1))\n",
        "\n",
        "baskets_rdd_with_random = baskets_rdd.map(random_lambda)\n",
        "\n",
        "# print(baskets_rdd.take(10))\n",
        "\n",
        "baskets_rdds = []\n",
        "for i in range(partitions_count):\n",
        "  baskets_rdds.append(baskets_rdd_with_random.filter(lambda x: x[1] == i).map(lambda x: x[0]))\n",
        "\n",
        "\n",
        "MIN_COUNTS = [ int(THRESHOLD * basket_rdd.count()) for basket_rdd in baskets_rdds]\n",
        "print('MIN_COUNTS are: ', MIN_COUNTS)\n",
        "\n",
        "frequent_itemsets_rdds_for_samples = []\n",
        "for i in range(partitions_count):\n",
        "  frequent_itemsets_rdds_for_samples.append(apriori(baskets_rdds[i], int(MIN_COUNTS[i]*0.9)))\n",
        "\n",
        "max_size = max(list(map(len, frequent_itemsets_rdds_for_samples)))\n",
        "\n",
        "\n",
        "for i in range(1, max_size+1):\n",
        "  frequent_itemsets_rdds_for_samples = list(filter(lambda x: len(x) >= i, frequent_itemsets_rdds_for_samples))\n",
        "\n",
        "  frequent_itemsets_rdd = sc.union([x[i-1] for x in frequent_itemsets_rdds_for_samples]).map(lambda x: x[0]).distinct()\n",
        "  _candidates = frequent_itemsets_rdd.collect()\n",
        "  def count_freq(basket):\n",
        "    candidates_present = []\n",
        "    for candidate in _candidates:\n",
        "      if set(candidate) <= set(basket):\n",
        "        candidates_present.append( (candidate,1) )\n",
        "    \n",
        "    return candidates_present\n",
        "\n",
        "  frequent_itemsets_rdd = baskets_rdd.flatMap(count_freq).reduceByKey(lambda x,y: x+y).filter(lambda x: x[1]>MIN_COUNT)\n",
        " \n",
        "  \n",
        "  print('Itemsets of size ', i, ', count: ', frequent_itemsets_rdd.count())\n",
        "  print('sample: ')\n",
        "  print(frequent_itemsets_rdd.take(10))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PbndzXrGlqop"
      },
      "source": [
        "# Results and Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXH3DxU5lqoq"
      },
      "source": [
        "With setting threshold to 0.02 or in the other hand by setting support equal to 30408 and on the whole data of the sample, frequent items is equal to 27 which a 10 sample of that is as below:\n",
        "((900107,), 38371), ((900155,), 45958), ((900207,), 35631), ((22010119,), 30749), ((900139,), 31477), ((900191,), 31379), ((100700824,), 34662), ((900244,), 61075), ((900164,), 37506), ((900236,), 41652)\n",
        "\n",
        "The most frequent 2-member-set is ((900212,900244),42733) which the right number of each set is the repeat of that set.\n",
        "\n",
        "For testing the code for bigger data, I get a sample of 0.01 from the data and put the threshold to 0.001 and the result is as below:\n",
        "\n",
        "SAMPLE_SIZE = 0.01\n",
        "\n",
        "THRESHOLD = 0.001\n",
        "\n",
        "MIN_COUNT is:  15\n",
        "\n",
        "\n",
        "\n",
        "Itemsets of size  2 , count:  811\n",
        "\n",
        "sample: \n",
        "\n",
        "[((101301, 900101), 30), ((900102, 100701100), 36), ((900182, 100701100), 33), ((145, 100700841), 20), ((900222, 900228), 28), ((900222, 100700868), 171), ((100700866, 100700868), 47), ((900234, 900276), 34), ((900235, 100700871), 41), ((209103, 900235), 18)]\n",
        "\n",
        "\n",
        "\n",
        "Itemsets of size  3 , count:  184\n",
        "\n",
        "sample: \n",
        "[((900212, 900244, 22009977), 23), ((631765, 900164, 900276), 17), ((631765, 900164, 100700820), 35), ((631765, 900276, 100700820), 21), ((900101, 900259, 100700841), 35), ((900155, 900222, 100700868), 50), ((205802, 900215, 900234), 19), ((142, 900215, 900234), 16), ((205802, 212802, 900233), 16), ((900215, 900234, 900256), 23)]\n",
        "\n",
        "\n",
        "\n",
        "Itemsets of size  4 , count:  11\n",
        "\n",
        "sample: \n",
        "[((22010087, 22010088, 22010094, 22010095), 28), ((900101, 900212, 900244, 100700839), 16), ((900193, 900212, 900244, 100700839), 16), ((900102, 900142, 900212, 900244), 18), ((900142, 900202, 900212, 900244), 16), ((900142, 900212, 900244, 900249), 17), ((900142, 900212, 900244, 100700853), 54), ((209103, 900265, 100700804, 100700834), 21), ((900142, 900152, 900212, 900244), 18), ((231, 900236, 900255, 100700841), 20)]\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b6782a3468882d2f7dcf69e0e9cdb62d5fca73d856fb697164e3caca48672c8a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
